{
 "metadata": {
  "name": "",
  "signature": "sha256:5fc4aa2c488c275da5ceb844913f8a2fc83d24cfddd3fd1e5e6234bd7c5307c5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import and setup modules we'll be using in this notebook\n",
      "import logging\n",
      "import os\n",
      "import sys\n",
      "import re\n",
      "import tarfile\n",
      "import itertools\n",
      "import json\n",
      "import math\n",
      "import collections\n",
      "from glob import glob\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "import nltk, nltk.classify.util, nltk.metrics\n",
      "from nltk.classify import NaiveBayesClassifier\n",
      "from nltk.probability import FreqDist, ConditionalFreqDist\n",
      "from nltk.collocations import TrigramCollocationFinder\n",
      "from nltk.metrics import BigramAssocMeasures, TrigramAssocMeasures\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import sklearn.cross_validation as cross_validation\n",
      "\n",
      "import gensim\n",
      "from gensim.utils import smart_open, simple_preprocess\n",
      "from gensim.corpora.wikicorpus import _extract_pages, filter_wiki\n",
      "from gensim.parsing.preprocessing import STOPWORDS\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib as mpl\n",
      "import seaborn as sns\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
      "logging.root.level = logging.INFO  # ipython sometimes messes up the logging setup; restore"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###################\n",
      "#\n",
      "# Useful variables\n",
      "#\n",
      "###################\n",
      "\n",
      "data = './yelp_data/'\n",
      "\n",
      "# All reviews\n",
      "data_reviews = pd.read_csv(data + 'yelp_academic_dataset_review.csv')\n",
      "\n",
      "# All businesses, though only their interesting columns\n",
      "interestingColumns = ['business_id', 'review_count', 'stars', 'latitude', 'longitude', 'type', 'categories']\n",
      "data_business = pd.read_csv(data + 'yelp_academic_dataset_business.csv')[interestingColumns]\n",
      "data_business = data_business.sort(['stars'], ascending=False)\n",
      "data_business.index = range(0, len(data_business))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Only restaurants\n",
      "data_restaurants = data_business[data_business['categories'].str.contains(\"R,e,s,t,a,u\")].sort(['review_count'], ascending=False)\n",
      "data_restaurants.index = range(0, len(data_restaurants))\n",
      "\n",
      "# Only restaurant reviews\n",
      "restaurant_ids = data_restaurants['business_id']\n",
      "restaurant_reviews = data_reviews[data_reviews['business_id'].isin(restaurant_ids)]\n",
      "restaurant_reviews.index = range(0, len(restaurant_reviews))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Number of restaurants: {}\".format(len(restaurant_ids))\n",
      "\n",
      "# Restaurants with a large number of reviews\n",
      "lots = 250\n",
      "restaurants_lots_of_reviews = data_restaurants[data_restaurants['review_count'] > lots]\n",
      "restaurants_lots_of_reviews_ids = restaurants_lots_of_reviews['business_id']\n",
      "print \"Number of restaurants with >{} reviews: {}\".format(lots, len(restaurants_lots_of_reviews))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of restaurants: 21892\n",
        "Number of restaurants with >250 reviews: 710\n"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###################\n",
      "#\n",
      "# Useful functions\n",
      "#\n",
      "###################\n",
      "\n",
      "def tokenize(text):\n",
      "    return [token for token in simple_preprocess(text) if token not in STOPWORDS]\n",
      "\n",
      "def iter_reviews(reviews):\n",
      "    \"\"\"Yield each review from the restaurant's reviews, as a `(id, tokens)` 2-tuple.\"\"\"\n",
      "    for idx, review in enumerate(reviews):\n",
      "        tokens = tokenize(review)\n",
      "        if len(tokens) < 5:\n",
      "            continue  # ignore short reviews\n",
      "        yield idx, tokens\n",
      "        \n",
      "class ReviewCorpus(object):\n",
      "    def __init__(self, dump_file, dictionary, clip_docs=None):\n",
      "        \"\"\"\n",
      "        Parse the first `clip_docs` reviews from array `dump_file`.\n",
      "        Yield each review in turn, as a list of tokens (unicode strings).\n",
      "        \n",
      "        \"\"\"\n",
      "        self.dump_file = dump_file\n",
      "        self.dictionary = dictionary\n",
      "        self.clip_docs = clip_docs\n",
      "    \n",
      "    def __iter__(self):\n",
      "        self.titles = []\n",
      "        for idx, tokens in itertools.islice(iter_reviews(self.dump_file), self.clip_docs):\n",
      "            self.titles.append(idx)\n",
      "            yield self.dictionary.doc2bow(tokens)\n",
      "    \n",
      "    def __len__(self):\n",
      "        return self.clip_docs\n",
      "    \n",
      "def topNWords(data_set, n):\n",
      "    review_stream = (tokens for _, tokens in itertools.islice(iter_reviews(data_set), 10000))\n",
      "\n",
      "    id2word_review = gensim.corpora.Dictionary(review_stream)\n",
      "\n",
      "    # ignore words that appear in less than 20 reviews or more than 10% reviews\n",
      "    #id2word_review.filter_extremes(no_below=20, no_above=0.1)\n",
      "\n",
      "    # create a stream of bag-of-words vectors\n",
      "    review_corpus = ReviewCorpus(data_set, id2word_review, clip_docs=5000)\n",
      "    vector = next(iter(review_corpus))\n",
      "\n",
      "    clipped_corpus = gensim.utils.ClippedCorpus(review_corpus, len(data_set) / 2)  # use fewer documents during training, LDA is slow\n",
      "    lda_model = gensim.models.LdaModel(clipped_corpus, num_topics=10, id2word=id2word_review, passes=4)\n",
      "\n",
      "    # select top 30 words for each of the LDA topics\n",
      "    top_words = [[word for _, word in lda_model.show_topic(topicno, topn=30)] for topicno in range(lda_model.num_topics)]\n",
      "\n",
      "    # get all top N words in all topics, as one large set\n",
      "    all_words = set(itertools.chain.from_iterable(top_words))\n",
      "\n",
      "    return all_words\n",
      "\n",
      "def importantReviews(reviews, n):\n",
      "    reviews_simple = reviews['text'].values\n",
      "    # Get the important words\n",
      "    importantWords = topNWords(reviews_simple, 30)\n",
      "    \n",
      "    # Give each review an \"importance score\"\n",
      "    review_scores = []\n",
      "    for idx, review in enumerate(reviews_simple):\n",
      "        tokens = tokenize(review)\n",
      "        score = 0\n",
      "\n",
      "        for word in importantWords:\n",
      "            score += tokens.count(word)\n",
      "\n",
      "        review_scores.append(score)\n",
      "\n",
      "    review_scores = np.array(review_scores)\n",
      "    review_scores = pd.DataFrame(review_scores, columns=['importance']).sort(['importance'], ascending=False)\n",
      "    \n",
      "    # Get the top n reviews\n",
      "    topReviews_idx = review_scores.head(n).index\n",
      "\n",
      "    # Top reviews\n",
      "    topReviews = reviews.ix[topReviews_idx]\n",
      "    \n",
      "    return topReviews\n",
      "\n",
      "def round_nearest_half(number):\n",
      "    return round(number * 2) / 2\n",
      "\n",
      "def predictRating(business_id):\n",
      "    # Get all the reviews for this business\n",
      "    reviews = restaurant_reviews[restaurant_reviews['business_id'] == business_id]\n",
      "    reviews.index = range(0, len(reviews))\n",
      "    \n",
      "    # Get the top 10 most important reviews\n",
      "    important_reviews = importantReviews(reviews, 10)\n",
      "    \n",
      "    # Average star rating based on top reviews\n",
      "    predictedRating = round_nearest_half(important_reviews['stars'].mean())\n",
      "\n",
      "    # Actual rating\n",
      "    actualRating = data_restaurants.ix[rest]\n",
      "\n",
      "    # Return a restaurant's predicted rating, along with their actual rating\n",
      "    return (predictedRating, actualRating['stars'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a test set\n",
      "test_size = 1\n",
      "restaurant_train, restaurant_test = cross_validation.train_test_split(restaurants_lots_of_reviews_ids, test_size=test_size, random_state=0)\n",
      "\n",
      "for restaurant in restaurant_test:\n",
      "    reviews = restaurant_reviews[restaurant_reviews['business_id'] == restaurant]\n",
      "    \n",
      "    print \"Restaurant {} has {} reviews.\".format(restaurant, len(reviews))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Restaurant foDMwBRGJvKw791v0AT7OA has 343 reviews.\n"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Predict ratings for test set\n",
      "predictions = []\n",
      "for restaurant in restaurant_test:\n",
      "    %time predictions.append(predictRating(restaurant))\n",
      "    \n",
      "predictions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.corpora.dictionary:built Dictionary(3940 unique tokens: [u'unimaginative', u'secondly', u'limited', u'unflavored', u'bc']...) from 342 documents (total 24419 corpus positions)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:using symmetric alpha at 0.1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:using serial LDA version on this node\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:running online LDA training, 10 topics, 4 passes over the supplied corpus of 171 documents, updating model once every 171 documents, evaluating perplexity every 171 documents, iterating 50x with a convergence threshold of 0.001000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:-12.380 per-word bound, 5330.2 perplexity estimate based on a held-out corpus of 171 documents with 12803 words\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #171/171\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.013*place + 0.012*vegas + 0.012*salad + 0.010*hugo + 0.007*service + 0.007*wine + 0.006*table + 0.005*like + 0.005*best + 0.005*rose\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.013*hugo + 0.011*salad + 0.011*place + 0.008*vegas + 0.007*cellar + 0.007*table + 0.007*experience + 0.007*meal + 0.006*rose + 0.006*restaurant\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.010*salad + 0.009*table + 0.007*restaurant + 0.007*best + 0.007*place + 0.006*great + 0.006*vegas + 0.005*service + 0.005*wine + 0.005*food\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.016*salad + 0.015*vegas + 0.011*old + 0.010*table + 0.009*food + 0.009*good + 0.008*like + 0.008*hugo + 0.006*chocolate + 0.006*place\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.014*salad + 0.013*place + 0.009*great + 0.008*meal + 0.008*hugo + 0.008*food + 0.007*table + 0.007*cellar + 0.007*rose + 0.007*like\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.017*salad + 0.011*good + 0.011*place + 0.009*service + 0.008*ordered + 0.008*meal + 0.007*great + 0.007*vegas + 0.007*food + 0.006*like\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.014*good + 0.013*salad + 0.010*vegas + 0.009*hugo + 0.007*place + 0.006*great + 0.006*food + 0.006*old + 0.006*best + 0.005*service\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.013*salad + 0.012*hugo + 0.012*food + 0.012*great + 0.012*place + 0.011*good + 0.011*vegas + 0.008*table + 0.008*service + 0.007*time\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.014*vegas + 0.013*hugo + 0.011*salad + 0.010*good + 0.008*cellar + 0.008*place + 0.007*table + 0.007*las + 0.006*time + 0.006*wine\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.013*vegas + 0.010*place + 0.010*great + 0.007*salad + 0.006*meal + 0.006*restaurant + 0.006*service + 0.005*rib + 0.004*ordered + 0.004*years\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic diff=5.620525, rho=1.000000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:-8.386 per-word bound, 334.6 perplexity estimate based on a held-out corpus of 171 documents with 12803 words\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:PROGRESS: pass 1, at document #171/171\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.011*place + 0.010*salad + 0.009*vegas + 0.008*hugo + 0.007*like + 0.007*best + 0.007*wine + 0.005*service + 0.005*chocolate + 0.005*dessert\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.014*salad + 0.014*hugo + 0.011*place + 0.009*table + 0.008*like + 0.006*experience + 0.006*amazing + 0.006*wine + 0.006*rose + 0.006*food\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.009*restaurant + 0.008*salad + 0.008*best + 0.007*place + 0.007*guy + 0.006*dinner + 0.006*table + 0.005*vegas + 0.005*excellent + 0.005*wine\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.018*vegas + 0.015*salad + 0.012*old + 0.010*like + 0.009*good + 0.009*table + 0.009*food + 0.008*hugo + 0.007*place + 0.007*cellar\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.017*salad + 0.012*place + 0.010*food + 0.009*meal + 0.008*great + 0.008*hugo + 0.008*vegas + 0.008*like + 0.008*cellar + 0.008*rose\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.017*salad + 0.012*good + 0.010*ordered + 0.010*service + 0.010*place + 0.010*meal + 0.009*great + 0.007*time + 0.006*chocolate + 0.006*vegas\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.013*good + 0.011*salad + 0.010*vegas + 0.009*place + 0.009*best + 0.008*food + 0.008*table + 0.007*hugo + 0.007*great + 0.007*old\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.013*salad + 0.013*hugo + 0.012*food + 0.012*great + 0.011*vegas + 0.011*good + 0.010*place + 0.008*table + 0.008*service + 0.008*nice\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.014*vegas + 0.013*hugo + 0.011*good + 0.010*salad + 0.009*place + 0.008*cellar + 0.008*wine + 0.008*table + 0.007*las + 0.006*chocolate\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.015*place + 0.012*vegas + 0.007*great + 0.006*years + 0.006*rib + 0.006*wife + 0.005*restaurant + 0.005*eat + 0.004*prime + 0.004*went\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic diff=1.948401, rho=1.000000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:-7.829 per-word bound, 227.4 perplexity estimate based on a held-out corpus of 171 documents with 12803 words\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:PROGRESS: pass 2, at document #171/171\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.010*salad + 0.009*place + 0.008*vegas + 0.008*hugo + 0.008*best + 0.008*wine + 0.007*like + 0.005*dessert + 0.005*chocolate + 0.005*service\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.014*salad + 0.013*hugo + 0.012*place + 0.009*table + 0.008*like + 0.006*amazing + 0.006*experience + 0.006*wine + 0.006*rose + 0.005*food\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.009*restaurant + 0.008*best + 0.008*salad + 0.007*place + 0.007*guy + 0.006*dinner + 0.006*excellent + 0.005*table + 0.005*day + 0.005*wine\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.018*vegas + 0.014*salad + 0.012*old + 0.010*like + 0.009*good + 0.009*hugo + 0.009*food + 0.008*table + 0.007*cellar + 0.007*place\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.018*salad + 0.011*place + 0.011*food + 0.009*meal + 0.009*vegas + 0.008*great + 0.008*like + 0.008*cellar + 0.008*hugo + 0.008*old\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.017*salad + 0.012*good + 0.010*place + 0.010*ordered + 0.010*service + 0.010*meal + 0.009*great + 0.007*time + 0.007*chocolate + 0.006*rose\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.011*good + 0.011*salad + 0.010*best + 0.010*vegas + 0.010*table + 0.010*food + 0.009*place + 0.007*service + 0.007*old + 0.007*great\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.013*salad + 0.013*hugo + 0.013*great + 0.012*food + 0.012*good + 0.011*vegas + 0.010*place + 0.009*table + 0.008*nice + 0.008*service\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.013*vegas + 0.013*hugo + 0.011*good + 0.010*salad + 0.009*place + 0.008*cellar + 0.008*wine + 0.007*table + 0.006*las + 0.006*chocolate\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.016*place + 0.012*vegas + 0.006*great + 0.006*rib + 0.006*years + 0.006*wife + 0.005*restaurant + 0.005*eat + 0.004*prime + 0.004*went\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic diff=0.296004, rho=1.000000\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:-7.755 per-word bound, 216.0 perplexity estimate based on a held-out corpus of 171 documents with 12803 words\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:PROGRESS: pass 3, at document #171/171\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #0 (0.100): 0.010*salad + 0.009*place + 0.008*vegas + 0.008*wine + 0.008*best + 0.007*hugo + 0.007*like + 0.005*dessert + 0.005*chocolate + 0.005*steak\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #1 (0.100): 0.014*salad + 0.013*hugo + 0.012*place + 0.009*table + 0.008*like + 0.006*amazing + 0.006*experience + 0.006*wine + 0.006*rose + 0.005*food\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #2 (0.100): 0.009*restaurant + 0.008*best + 0.007*salad + 0.007*place + 0.007*guy + 0.006*dinner + 0.006*excellent + 0.005*day + 0.005*wine + 0.005*vegas\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #3 (0.100): 0.018*vegas + 0.014*salad + 0.012*old + 0.010*like + 0.009*good + 0.009*hugo + 0.009*food + 0.008*table + 0.007*cellar + 0.007*place\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #4 (0.100): 0.018*salad + 0.011*place + 0.011*food + 0.009*meal + 0.009*vegas + 0.008*great + 0.008*like + 0.008*cellar + 0.008*hugo + 0.008*old\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #5 (0.100): 0.017*salad + 0.011*good + 0.010*place + 0.010*service + 0.010*ordered + 0.010*meal + 0.009*great + 0.007*time + 0.007*chocolate + 0.006*rose\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #6 (0.100): 0.011*salad + 0.011*good + 0.010*table + 0.010*best + 0.010*vegas + 0.010*food + 0.009*place + 0.007*service + 0.007*old + 0.007*great\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #7 (0.100): 0.014*salad + 0.013*hugo + 0.013*great + 0.013*food + 0.012*good + 0.011*vegas + 0.010*place + 0.009*table + 0.009*nice + 0.009*service\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #8 (0.100): 0.013*hugo + 0.013*vegas + 0.010*good + 0.009*salad + 0.008*place + 0.008*cellar + 0.008*wine + 0.007*table + 0.006*chocolate + 0.006*las\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic #9 (0.100): 0.016*place + 0.012*vegas + 0.006*great + 0.006*years + 0.006*wife + 0.006*rib + 0.005*restaurant + 0.005*eat + 0.005*prime + 0.005*went\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:gensim.models.ldamodel:topic diff=0.089483, rho=1.000000\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 127,
       "text": [
        "[(3.5, 4.0)]"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculate total error\n",
      "error = 0.0\n",
      "for prediction in predictions:\n",
      "    error += abs(prediction[0] - prediction[1]) / prediction[1]\n",
      "    \n",
      "print \"Total error: {}%\".format(error / len(predictions) * 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total error: 12.5%\n"
       ]
      }
     ],
     "prompt_number": 128
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}